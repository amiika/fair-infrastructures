"ID","Type","Name","Documentation","Specialization"
"id-3b7d80b7034c4c77bf160c6465a684d0","ArchimateModel","Reference Architecture for FAIR Data Infrastructures","Reference Architecture for FAIR Data Infrastructures",""
"id-20449b93497848efaf243c6046c8c870","Capability","Access Management","The ability to manage user access and permissions across datasets and systems, ensuring that only authorized users can interact with sensitive data.
",""
"id-c8ee4e676ed746be9df0ca6997190dfa","Capability","Access Management (copy)","The ability to manage user access and permissions across datasets and systems, ensuring that only authorized users can interact with sensitive data.
",""
"id-d285ecf39fc743f0b83198516539941a","Capability","Actionable Data Management Plan","Capability to create machine-readable data management plans, share and update them through interfaces. Ability to actively utilize the machine-readable features of the data management plan to facilitate the researcher's work throughout the research process.",""
"id-7fc3bc52a4944ca6a49f1aa2c6a59a23","Capability","Actionable Data Management Plan (copy)","Capability to create machine-readable data management plans, share and update them through interfaces. Ability to actively utilize the machine-readable features of the data management plan to facilitate the researcher's work throughout the research process.",""
"id-8fe13eb69bcf47fcb6ad7781c13e469b","Capability","Anonymization and Pseudonymization","",""
"id-594d86fff4a04cca8216057f4796c9ed","Capability","Anonymization and Pseudonymization (copy)","",""
"id-8593a39dcfbe463eb4c8aae5093bcd50","Capability","API Management","Skills in developing and managing APIs (Application Programming Interfaces) that enable efficient and secure access to datasets and research tools.",""
"id-8b3868b76c5b482397573406af8a8862","Capability","API Management (copy)","Skills in developing and managing APIs (Application Programming Interfaces) that enable efficient and secure access to datasets and research tools.",""
"id-b0f86f4a002f4f0baf61d02e758acad9","Capability","Artificial Intelligence","Expertise in leveraging machine learning and artificial intelligence to gain insights from large datasets, including the ability to apply advanced analytics techniques for pattern recognition, prediction, and data mining.",""
"id-449ace69e9f14a6dbd52924ddfd37c44","Capability","Artificial Intelligence (copy)","Expertise in leveraging machine learning and artificial intelligence to gain insights from large datasets, including the ability to apply advanced analytics techniques for pattern recognition, prediction, and data mining.",""
"id-046d158a7cbd44d2ab33f88160a48e3e","Capability","Change Management","The knowledge to plan and manage changes in data infrastructure, governance policies, or technology systems to adapt to evolving research needs.",""
"id-018c2a91516c448ebd43aa53add04b1d","Capability","Change Management (copy)","The knowledge to plan and manage changes in data infrastructure, governance policies, or technology systems to adapt to evolving research needs.",""
"id-18bb30150ceb4938bf48e713e7b2f56d","Capability","Cloud Architectures","The ability to leverage cloud computing resources to build scalable, flexible, and cost-effective data infrastructures for research.",""
"id-51357ff8e4544e50bf3c724dd75e0acb","Capability","Cloud Architectures (copy)","The ability to leverage cloud computing resources to build scalable, flexible, and cost-effective data infrastructures for research.",""
"id-e67560f9e0874b0195e36657cca8a4d8","Capability","Cumulative and Big Data","Experise in transfer, storage, and processing of large data volumes. Knowledge in applying data compression techniques to manage large volumes of data without sacrificing data quality or performance. Skills in managing and processing datasets that grow incrementally over time. Expertise in handling and processing large datasets, including the infrastructure and computational techniques required to manage them effectively.",""
"id-7f174fbe918241f58056d16d43e3b939","Capability","Cumulative and Big Data (copy)","Experise in transfer, storage, and processing of large data volumes. Knowledge in applying data compression techniques to manage large volumes of data without sacrificing data quality or performance. Skills in managing and processing datasets that grow incrementally over time. Expertise in handling and processing large datasets, including the infrastructure and computational techniques required to manage them effectively.",""
"id-349dacdcc8fc488db89de82a667b5016","Capability","Data Analytics And Reporting","Skills in applying analytical techniques to interpret large datasets and generate insights that inform research findings and reporting.",""
"id-c87fe99723d4483f9865c87b10d0ef1a","Capability","Data Analytics And Reporting (copy)","Skills in applying analytical techniques to interpret large datasets and generate insights that inform research findings and reporting.",""
"id-e906de5ff75848b3abb0ff2217cdffea","Capability","Data Citation and Attribution","Knowledge in assigning proper citations and credit for datasets, ensuring that data creators are appropriately acknowledged in research outputs.",""
"id-7a43c9a733694e1faeaacddbdf1734af","Capability","Data Citation and Attribution (copy)","Knowledge in assigning proper citations and credit for datasets, ensuring that data creators are appropriately acknowledged in research outputs.",""
"id-f3e9121bf2ab42fd9536f4ccb294a279","Capability","Data Curation","Skills in managing and preserving datasets over time, including the selection, organization, and validation of research data for long-term use.",""
"id-4653489684474149aaa47428f978af34","Capability","Data Curation (copy)","Skills in managing and preserving datasets over time, including the selection, organization, and validation of research data for long-term use.",""
"id-87c14457d9344b0dba1674b0a3aed0fe","Capability","Data Discovery Architecture","Skills in designing infrastructures that allow researchers and other stakeholders to find and access relevant datasets",""
"id-3d5c8126ed5e4a869a247e4345f7ad79","Capability","Data Discovery Architecture (copy)","Skills in designing infrastructures that allow researchers and other stakeholders to find and access relevant datasets",""
"id-f85f612b24764b0cb07f29d208447ce8","Capability","Data Encryption","Skills in applying encryption techniques to protect data at rest and in transit, ensuring its confidentiality and integrity.",""
"id-e302d3138b594b169331ee0a60ce149c","Capability","Data Encryption (copy)","Skills in applying encryption techniques to protect data at rest and in transit, ensuring its confidentiality and integrity.",""
"id-1ffe206f31e14e9c91c437fd7e4e5108","Capability","Data Engineering","",""
"id-b14b5061efbf4c668592164cd4701288","Capability","Data Engineering","Skills needed to build, optimize, and manage the systems and pipelines that store, process, and analyze research data. ",""
"id-ef0df9bf75d94dcab3bed5303b4361b9","Capability","Data Engineering (copy)","Skills needed to build, optimize, and manage the systems and pipelines that store, process, and analyze research data. ",""
"id-a2e560a54d95435fb7cee609c2ab5be4","Capability","Data Ethics","Expertise in ensuring that data collection, use, and dissemination uphold ethical standards, particularly when handling sensitive or personal data.",""
"id-a978021dd1914b6ea4f94fad81e5b392","Capability","Data Ethics (copy)","Expertise in ensuring that data collection, use, and dissemination uphold ethical standards, particularly when handling sensitive or personal data.",""
"id-c7c229b3f9604a7c90a1bbdacb966584","Capability","Data Licensing","Understanding various types of data licenses (e.g., open, restricted) and applying them to protect intellectual property while enabling appropriate data sharing.",""
"id-937a709069c4469fa7c4cb7a7c3f7eff","Capability","Data Licensing (copy)","Understanding various types of data licenses (e.g., open, restricted) and applying them to protect intellectual property while enabling appropriate data sharing.",""
"id-b7af6d7507e54cd38b388608b154b89b","Capability","Data Lineage","Experise in defining data workflows that preserves the history and lineage of the data to maintain accountability and transparency in data use.",""
"id-82ed28c14a8c4a07993f512bb429f722","Capability","Data Lineage (copy)","Experise in defining data workflows that preserves the history and lineage of the data to maintain accountability and transparency in data use.",""
"id-ef47e07c507a48d3bd3bb77d0df4d04e","Capability","Data Policies","Knowledge of creating and enforcing institutional data policies that govern the collection, storage, sharing, and use of data.",""
"id-6106f4a22ef04f05940a12bd0362f9cb","Capability","Data Policies (copy)","Knowledge of creating and enforcing institutional data policies that govern the collection, storage, sharing, and use of data.",""
"id-5ca4f7a69bcd42238e141705e5b91772","Capability","Data Preservation","Expertise to protect data from being lost or destroyed using national guidelines and research domain spesific best practices",""
"id-2779ec81376d4b5f97f03dc958cadb1e","Capability","Data Processing","The capability to design, optimize, and run data processing workflows that clean, transform, and analyze raw data for domain-spesific research purposes. ",""
"id-4c5c92c340a14d97a7604c436f867fd8","Capability","Data Processing (copy)","The capability to design, optimize, and run data processing workflows that clean, transform, and analyze raw data for domain-spesific research purposes. ",""
"id-f2b30f99ea0d4d2ab51699242871845d","Capability","Data Publication","",""
"id-2fac2a4a728346e7a5e5abeb31d69364","Capability","Data Quality","Expertise in ensuring the accuracy, completeness, and consistency of data throughout its lifecycle, including the identification and resolution of data quality issues.",""
"id-57d71b67754241268cad3f46ab107c67","Capability","Data Quality (copy)","Expertise in ensuring the accuracy, completeness, and consistency of data throughout its lifecycle, including the identification and resolution of data quality issues.",""
"id-dfdd74d1ea4e427293b3a0f91a25ec64","Capability","Data Rights and Legal Compliance","The knowledge and practices required to ensure that research data is managed and shared according to applicable laws, licenses, regulations and ethical guidelines.",""
"id-f4f21951fced4828b5edae4106b0718a","Capability","Data Rights and Legal Compliance (copy)","The knowledge and practices required to ensure that research data is managed and shared according to applicable laws, licenses, regulations and ethical guidelines.",""
"id-de7b342f1d4a4483a3089516cb6932f0","Capability","Data Security","Expertise in implementing security measures, including encryption, access controls, and monitoring, to protect research data from unauthorized access or breaches.",""
"id-603b3231a1b141e29b8959a5794b1be4","Capability","Data Security (copy)","Expertise in implementing security measures, including encryption, access controls, and monitoring, to protect research data from unauthorized access or breaches.",""
"id-b6936fa37d594b098ac7a79764571362","Capability","Data Stewardship","",""
"id-ad548d0fe72f4c7f8766cd8e754ce008","Capability","Data Stewardship","The capability to oversee data throughout its lifecycle, ensuring it remains accurate, accessible, and aligned with institutional policies. Skills in managing the various stages of the data lifecycle (collection, generation, gathering, processing, analysis, publication, sharing, preservation, archiving, disposal, reuse).",""
"id-9a6ecd006a9741a3b9c8ff9a4cce7db6","Capability","Data Stewardship (copy)","The capability to oversee data throughout its lifecycle, ensuring it remains accurate, accessible, and aligned with institutional policies. Skills in managing the various stages of the data lifecycle (collection, generation, gathering, processing, analysis, publication, sharing, preservation, archiving, disposal, reuse).",""
"id-622a90b1a9384b7abe96ae1438cf677b","Capability","Data Valuation and Meritation","Expertise in creating policies and evaluating the value of data based on its quality, relevance, and potential for reuse within research contexts and across domains.",""
"id-f52740e96c534c318020ea912304b074","Capability","Data Valuation and Meritation (copy)","Expertise in creating policies and evaluating the value of data based on its quality, relevance, and potential for reuse within research contexts and across domains.",""
"id-782b35f31520404a96c1d76b984b76b2","Capability","Data Versioning and Provenance","Expertise in creating metadata for tracking changes to datasets over time and ensuring a record of their origin, modifications, and history.",""
"id-658d0e2fd6994c5ab9fab5a219251803","Capability","Data Versioning and Provenance (copy)","Expertise in creating metadata for tracking changes to datasets over time and ensuring a record of their origin, modifications, and history.",""
"id-49a42c9610314fa0ba996ac403b9d66e","Capability","Data Visualization","Skills in visualizing large datasets and generating insightful reports, allowing researchers to easily interpret and communicate their findings.",""
"id-848180646b3f41ea9477c023e68ea991","Capability","Data Visualization (copy)","Skills in visualizing large datasets and generating insightful reports, allowing researchers to easily interpret and communicate their findings.",""
"id-e194addcd6ed4bac8f5411823de676d6","Capability","Database Management","The capability to design, implement, and maintain efficient and secure databases that store and organize research data.",""
"id-24e1bc1904bf4223b612efce8c5e4741","Capability","Database Management (copy)","The capability to design, implement, and maintain efficient and secure databases that store and organize research data.",""
"id-5d556ffc08794197b8f0ffd211593b91","Capability","Domain Architectures","Knowledge of designing domain specific data architectures tailored to particular research area, ensuring that reasearch area specific needs are met.",""
"id-dcbd87e3fc81499995e688e175e2ea5a","Capability","Domain Architectures (copy)","Knowledge of designing domain specific data architectures tailored to particular research area, ensuring that reasearch area specific needs are met.",""
"id-3578c5ac86f04bd4b73d0997f59f6209","Capability","Edge Computing","Skills in processing data at the edge of the network, close to the data source, reducing latency and enhancing the efficiency of real-time data analysis.",""
"id-eb83cb1e16a24a20a60f18987a267e77","Capability","Edge Computing (copy)","Skills in processing data at the edge of the network, close to the data source, reducing latency and enhancing the efficiency of real-time data analysis.",""
"id-6cc6d10a00f8434884c13b73f85b730c","Capability","FAIR Principles","Expertise in applying the principles of Findability, Accessibility, Interoperability, and Reusability to research data management practices.",""
"id-787d42b9370445e5b2caf5b85a5e8337","Capability","FAIR Principles (copy)","Expertise in applying the principles of Findability, Accessibility, Interoperability, and Reusability to research data management practices.",""
"id-ca89a011d6d44191921e3035a9b99d9f","Capability","Green Data Architecture","Knowledge of designing energy-efficient data systems that minimize environmental impact, promoting sustainability in research infrastructures.",""
"id-b6784cd8c4a246719479ce4d1465b630","Capability","Green Data Architecture (copy)","Knowledge of designing energy-efficient data systems that minimize environmental impact, promoting sustainability in research infrastructures.",""
"id-9a39d3188be54778a781a8ed15f70253","Capability","Information Architecture","Expertise needed to design FAIR information architectures that enhances data usability, findability, accessibility and interoperability.",""
"id-6e62d25fb6024f08899ef2277727c577","Capability","Information Architecture (copy)","Expertise needed to design FAIR information architectures that enhances data usability, findability, accessibility and interoperability.",""
"id-2e902bfd749d4fb18dd4d027ee67d7c5","Capability","Infrastructure scalability","Competencies in designing and maintaining infrastructures that can scale up to accommodate growing data volumes and increased complexity.",""
"id-baae3b266fa84c24811c79890c1df1c4","Capability","Infrastructure scalability (copy)","Competencies in designing and maintaining infrastructures that can scale up to accommodate growing data volumes and increased complexity.",""
"id-a3de48cda33343bdb4cf68db01d819df","Capability","Integration Development","The ability to integrate disparate data systems and tools, ensuring seamless interaction and data exchange across platforms and applications.",""
"id-db1346c6d9b04c7f8b7f675663579471","Capability","Integration Development (copy)","The ability to integrate disparate data systems and tools, ensuring seamless interaction and data exchange across platforms and applications.",""
"id-5582883d01d14e8586efb30cc9e9dc61","Capability","Intellectual Property Rights","Skills in understanding, protecting and managing intellectual property rights related to data ownership and usage within the framework of research.",""
"id-7201025cdab1400e9c3633215d83ee83","Capability","Intellectual Property Rights (copy)","Skills in understanding, protecting and managing intellectual property rights related to data ownership and usage within the framework of research.",""
"id-5e1be14e39c54792b454f7c165a1f79d","Capability","Interoperability","",""
"id-eeb45c4bb12a41d9a9dda619010d9a7f","Capability","Interoperability and Standards","Knowledge of relevant data standards within specific fields and understanding and applying of generic data standards (such as W3C standards, ISO, etc.) to ensure that datasets can be exchanged and understood across different systems and disciplines.",""
"id-49f5ba9c2b0a408f888737c6bd4ea4bc","Capability","Interoperability and Standards (copy)","Knowledge of relevant data standards within specific fields and understanding and applying of generic data standards (such as W3C standards, ISO, etc.) to ensure that datasets can be exchanged and understood across different systems and disciplines.",""
"id-ca26f5f1d38746db97f05f2d725e03f4","Capability","Interoperability Frameworks","Expertise in designing and implementing architectures that ensure seamless data exchange and compatibility between different systems, platforms, and formats. Ensuring that data management systems can interact with other systems, allowing secure data exchange and cross-collaboration. Capability to co-develop data specifications supporting interoperability within and across research domains. Readiness to apply recommendations and standards, and participate in national and international standardization organizations.

",""
"id-39ed85555eaa41baae9ed655b1387c59","Capability","Interoperability Frameworks (copy)","Expertise in designing and implementing architectures that ensure seamless data exchange and compatibility between different systems, platforms, and formats. Ensuring that data management systems can interact with other systems, allowing secure data exchange and cross-collaboration. Capability to co-develop data specifications supporting interoperability within and across research domains. Readiness to apply recommendations and standards, and participate in national and international standardization organizations.

",""
"id-29b1c37f61f94d2dbaa98dc68a6dece2","Capability","Legal Framework","Knowledge of relevant laws and regulations governing data use, such as GDPR, copyright law, and privacy policies, ensuring compliance in the research domain.",""
"id-dad343a48d9c4823a11820a4555fabf1","Capability","Legal Framework (copy)","Knowledge of relevant laws and regulations governing data use, such as GDPR, copyright law, and privacy policies, ensuring compliance in the research domain.",""
"id-5923835d61754ee8b8bdfc601fca229b","Capability","Master and Reference Data Architecture","The ability to ensure the consistency, accuracy, and integrity of master data across multiple systems, datasets and research projects. Expertise in organizing and managing reference datasets, which provide consistent data for use across research projects and domains.",""
"id-21ac772d51324ad8b471fa3ad79b30b4","Capability","Master and Reference Data Architecture (copy)","The ability to ensure the consistency, accuracy, and integrity of master data across multiple systems, datasets and research projects. Expertise in organizing and managing reference datasets, which provide consistent data for use across research projects and domains.",""
"id-31fe31dc2f194692834381d5daaf7c9a","Capability","Master Data Management (copy)","The ability to ensure the consistency, accuracy, and integrity of master data across multiple datasets and research projects.",""
"id-c93cacbf865f41949a37064d62e5fbb1","Capability","Metadata Architecture","Expertise needed to develop and manage metadata that support the effective discovery, interpretation, use and reuse of research data.",""
"id-8449e9074dcc44e2b97c8d602f2dc273","Capability","Metadata Architecture (copy)","Expertise needed to develop and manage metadata that support the effective discovery, interpretation, use and reuse of research data.",""
"id-68fc7f28bab4477f83e0ea69d2e0d083","Capability","Metadata Harmonization and Crosswalks","Skills in building harmonizing architectures and reconciling and mapping different metadata schemas across disciplines, promoting interoperability and cross-disciplinary research.",""
"id-7caf430833f94e47baf78c54f05b5a7d","Capability","Metadata Harmonization and Crosswalks (copy)","Skills in building harmonizing architectures and reconciling and mapping different metadata schemas across disciplines, promoting interoperability and cross-disciplinary research.",""
"id-79cf5bb7ab1f4bf6a87b62076dfbde5d","Capability","MyData","",""
"id-a74a08ca7ea7453d85a97aa0c5fe3837","Capability","MyData Principles","Skills in managing personal data with a user-centric approach, allowing individuals to control the usage, sharing, and storage of their data.",""
"id-98e6839682af4d81a0c488181dc5f709","Capability","MyData Principles (copy)","Skills in managing personal data with a user-centric approach, allowing individuals to control the usage, sharing, and storage of their data.",""
"id-1d40e44146e94df995f9e2b15aa19a3b","Capability","Ontology Development","Knowledge of creating and managing ontologies and linked data to facilitate understanding, data categorization and interoperability.",""
"id-76e1870bcb0b426e9ce55b78516a995c","Capability","Ontology Development (copy)","Knowledge of creating and managing ontologies and linked data to facilitate understanding, data categorization and interoperability.",""
"id-e4a927f0c82b4e09828df3f009d25d59","Capability","Persistent Identifiers","The ability to assign and manage unique, permanent identifiers (e.g., DOI, ORCID) to datasets, ensuring long-term findability and reference. The use of persistent identifiers enhances data management and enables, for example, the formation of knowledge graphs and supports the repeatability and automation of research.",""
"id-7b7bbf3a175b46cfaf0fb5fde0375c40","Capability","Persistent Identifiers (copy)","The ability to assign and manage unique, permanent identifiers (e.g., DOI, ORCID) to datasets, ensuring long-term findability and reference. The use of persistent identifiers enhances data management and enables, for example, the formation of knowledge graphs and supports the repeatability and automation of research.",""
"id-9cf545de5bfe4819a86c6aceaabe2951","Capability","Preservation Architecture","Expertise in designing infrastructure for the long-term storage and preservation of datasets, ensuring their availability for future use.",""
"id-714b2a1542d74384b6872e82d608da2d","Capability","Preservation Architecture (copy)","Expertise in designing infrastructure for the long-term storage and preservation of datasets, ensuring their availability for future use.",""
"id-27a9768187094d538d3f6947ce493e26","Capability","Project Funding","Skills in identifying funding opportunities, writing grant applications, and securing financial support for research projects and data infrastructure.",""
"id-c3cb85eb2ec34e1c90ca74a2b74fb70a","Capability","Project Funding (copy)","Skills in identifying funding opportunities, writing grant applications, and securing financial support for research projects and data infrastructure.",""
"id-cfdbae2759b343a39957116133ad9b65","Capability","Project planning","The capability to define research objectives, timelines, resources and requirements, ensuring efficient execution and alignment with institutional goals and funding agencies requirements.",""
"id-f68f58c0b8df4ea7a1790bea59487cb9","Capability","Project planning (copy)","The capability to define research objectives, timelines, resources and requirements, ensuring efficient execution and alignment with institutional goals and funding agencies requirements.",""
"id-60c0580c6227424eb397d51843b3d983","Capability","Real-Time Data Processing","Expertise in processing streaming data in real-time, useful in fields like sensor data analysis or financial research.",""
"id-26641739d4184808934679a10b63ff6c","Capability","Real-Time Data Processing (copy)","Expertise in processing streaming data in real-time, useful in fields like sensor data analysis or financial research.",""
"id-68713762d8d347fcb20aabe8fee860af","Capability","Reproducible Research","The ability to design research workflows and processes that allow for data and research findings to be consistently reproduced by others, promoting transparency.",""
"id-5f607401a8d94a2c8c34b03494e2b8c0","Capability","Reproducible Research (copy)","The ability to design research workflows and processes that allow for data and research findings to be consistently reproduced by others, promoting transparency.",""
"id-43f02b66008544b3ac6250e3fcdb4608","Capability","Research Data Governance","Planning data management to support the research process. Capability to comprehensively develop support processes and services toward interoperable data management planning and guidance. Requires collaboration between organizations providing support services at both local and national levels.

Research Data Governance encompasses the skills and knowledge required to establish and enforce policies, procedures, and frameworks that govern the management of research data. It ensures that data is handled responsibly, ethically, and in compliance with legal and institutional standards. Key areas include risk management, policy development, data valuation, and fostering collaborations within and outside institutions. Governance ensures that data is used effectively, securely, and sustainably, supporting long-term research goals and data stewardship.",""
"id-5f7b4e1b2a314eab869f53d92649a072","Capability","Research Data Governance (copy)","Planning data management to support the research process. Capability to comprehensively develop support processes and services toward interoperable data management planning and guidance. Requires collaboration between organizations providing support services at both local and national levels.

Research Data Governance encompasses the skills and knowledge required to establish and enforce policies, procedures, and frameworks that govern the management of research data. It ensures that data is handled responsibly, ethically, and in compliance with legal and institutional standards. Key areas include risk management, policy development, data valuation, and fostering collaborations within and outside institutions. Governance ensures that data is used effectively, securely, and sustainably, supporting long-term research goals and data stewardship.",""
"id-382b11b7d8d546c9bf8eb22da4d12808","Capability","Research Data Management","Capability to produce and manage data throughout the research process, ensuring sufficient information on the origin and lifecycle of the data. Research data is managed throughout its lifecycle, ensuring its controlled collection, creation, sharing, storage, archiving, destruction, and publication.",""
"id-02711e20a05444d3a7b33da5adfcc363","Capability","Research Data Management","",""
"id-371f5b966910416c8a2a6f1279b7be34","Capability","Research Data Management (copy)","Capability to produce and manage data throughout the research process, ensuring sufficient information on the origin and lifecycle of the data. Research data is managed throughout its lifecycle, ensuring its controlled collection, creation, sharing, storage, archiving, destruction, and publication.",""
"id-d6c554866a634b4f95630701f35a931a","Capability","Research Data Process Development","Expetise to design, optimize, and implement processes that support the full lifecycle of research data. ",""
"id-ae9db20cd1eb4095bc6d25b65665f4e2","Capability","Research Data Process Development (copy)","Expetise to design, optimize, and implement processes that support the full lifecycle of research data. ",""
"id-ff982b27c376480987fffd219dec06b1","Capability","Research Dataset Metadata","Skills in creating and managing metadata (DCAT, DataCite, etc.) that accurately describes research datasets, improving their accessibility and reusability.
",""
"id-3ff3bf7de3eb476c8a388af5c4a4acbb","Capability","Research Dataset Metadata (copy)","Skills in creating and managing metadata (DCAT, DataCite, etc.) that accurately describes research datasets, improving their accessibility and reusability.
",""
"id-e781a6c746a54caea488cc854278cb86","Capability","Research Infrastructure Architecture","Expertise needed to design, build, and maintain the physical and digital architectures that support research data management in different research domains",""
"id-0d1d419e56824169898ca8cbd9e9fa6a","Capability","Research Infrastructure Architecture (copy)","Expertise needed to design, build, and maintain the physical and digital architectures that support research data management in different research domains",""
"id-14241a891ccc4ad3af19cafb3437a9ef","Capability","Research Methods","Understanding a variety of quantitative and qualitative research methodologies and how data management is embedded within these methods.",""
"id-0823d941e44245339bf5723f546ba0eb","Capability","Research Methods (copy)","Understanding a variety of quantitative and qualitative research methodologies and how data management is embedded within these methods.",""
"id-6890fd62f34b4ee9b5668e9127d3eccb","Capability","Research Networking and Collaboration","Capability to leverage national and international collaboration to advance data management. Skills to foster partnerships between researchers, institutions, and other stakeholders to facilitate the exchange of knowledge and data. ",""
"id-1dc15be77722459d934d91aa7ed6b573","Capability","Research Networking and Collaboration (copy)","Capability to leverage national and international collaboration to advance data management. Skills to foster partnerships between researchers, institutions, and other stakeholders to facilitate the exchange of knowledge and data. ",""
"id-4520c07223f8499195f0f8e76de51132","Capability","Research, Development and Innovation","Capability to commercialize research results, especially research data.",""
"id-9c8571ae50904d9fa54e64513ea2fac8","Capability","Research, Development and Innovation (copy)","Capability to commercialize research results, especially research data.",""
"id-3c6e8e1321a64c2fb3b5470a5c4078b0","Capability","Risk Management","Ability to identify, assess, and mitigate risks related to research data handling, storage, sharing, and legal compliance.",""
"id-c126a57cdaa242b180ddec7b92b59a46","Capability","Risk Management (copy)","Ability to identify, assess, and mitigate risks related to research data handling, storage, sharing, and legal compliance.",""
"id-d6b7c93b174349fb8e582d60d2fed089","Capability","Scientific computing","Skills in leveraging high-performance computing (HPC) and other advanced computing systems to process and analyze large, complex datasets.",""
"id-e87dc43e3cc44344a4217384ec89498d","Capability","Scientific computing (copy)","Skills in leveraging high-performance computing (HPC) and other advanced computing systems to process and analyze large, complex datasets.",""
"id-fe785d2d74a34fc8aa8c742ba8b9d1a0","Capability","Search Engine Optimization","The ability to optimize metadata and dataset descriptions to ensure that research data is easily discoverable through search engines.",""
"id-e29ea5c6c34c4c4594d30c7d6ea0a470","Capability","Search Engine Optimization (copy)","The ability to optimize metadata and dataset descriptions to ensure that research data is easily discoverable through search engines.",""
"id-0d1cddf61559490da2bf829c867a8d25","Capability","Sensitive Data Architecture","Skills in building data infrastructures that securely store and manage sensitive or confidential information, adhering to privacy regulations. ",""
"id-d70d0088dfec45e791c03b10cc075cfb","Capability","Sensitive Data Architecture (copy)","Skills in building data infrastructures that securely store and manage sensitive or confidential information, adhering to privacy regulations. ",""
"id-fabf263001f347bc8b7ee403aa8e8882","Capability","Service Development","Expertise in developing and enhancing research data services, ensuring they are accessible, user-friendly, and aligned with the needs of researchers and institutions.",""
"id-352d51d150ff457a9a38f1d73acc08a3","Capability","Service Development (copy)","Expertise in developing and enhancing research data services, ensuring they are accessible, user-friendly, and aligned with the needs of researchers and institutions.",""
"id-88fa7707e6bc4bba9c9a6659b88c4c64","Capability","Software Development","Generic expertise in software development and programming languages",""
"id-607a64e1c2774e7d8367fb0aa2fb4d1e","Capability","Software Development (copy)","Generic expertise in software development and programming languages",""
"id-b2681c714ee8426485e005ed76222cf4","Capability","User Management","",""
"id-fd7e03b70020448a901ddb0e9ff56e57","Capability","Workflows, Pipelines and Deployment","Expertise in designing and automating data workflows and pipelines to efficiently process and move data from source to storage and analysis. Skills in using container technologies (e.g., Docker, Kubernetes) to deploy scalable, portable data processing environments.",""
"id-c9646329066c42ffb3b4718d4dd4c4dc","Capability","Workflows, Pipelines and Deployment (copy)","Expertise in designing and automating data workflows and pipelines to efficiently process and move data from source to storage and analysis. Skills in using container technologies (e.g., Docker, Kubernetes) to deploy scalable, portable data processing environments.",""
"id-cbd5551fe1654b84bfce597fe99e9531","ValueStream","Value Stream","",""
"id-ffccfa5493dc432082d3c1258f8cee8a","BusinessActor","Business Actor","",""
"id-b44cd6ed55a648d49df02398675e0a02","BusinessActor","Curator","",""
"id-7f24b7d034e840528e2068c0674d4ce9","BusinessActor","Director","",""
"id-98fa77eb8210446aadcb2a72b3575fdb","BusinessActor","Funder","",""
"id-046412b68241467e841cf54bd140da82","BusinessActor","Project support","",""
"id-591af9fc88994522b8974450cb138bdc","BusinessActor","Publication Support","",""
"id-1d90bb64fa264c84b1caf13713b9ec24","BusinessActor","Research Support","",""
"id-6cc4ef14112740aca52a39f64454a867","BusinessActor","Researcher","",""
"id-c642d92bc6ed4c839a8555d780f5cb19","BusinessActor","Service Owner","",""
"id-c96086e82a3c4a28b78d3d565c52c60e","BusinessActor","Technology support","",""
"id-25b669f4b2fd485187a8863cf5e50043","BusinessCollaboration","Business Collaboration","",""
"id-d92e92ce80764b6b91e7cc871ec5ca7f","BusinessCollaboration","Data Preservation","",""
"id-60eadda102da4b3b938a3ad49a3d440b","BusinessCollaboration","Data Standardization","Collaborative process for developing common standards for data and ensuring that data across different systems or organizations conforms to agreed format and structure.",""
"id-a0af72bbe7fe43e69ec45f25b678ffb6","BusinessCollaboration","FAIR Data Lifecycle","",""
"id-88bdc61b66084512af90cb6b90fdfd62","BusinessCollaboration","Research Data Management","",""
"id-8c22b4aaeedc4b4dbf6a50a61e8af0fc","BusinessEvent","Business Event","",""
"id-ac2621a15c2d4b6986b01ee1dd69d9a6","BusinessFunction","FAIR Data Support","",""
"id-d233737f466f45519da3107b45acfd3f","BusinessFunction","FAIR Publication Support","",""
"id-039b2b7a1d91446f9a68e93031ae1e70","BusinessFunction","FAIR Research Support","",""
"id-139fa7c3e0d34f46a9a57b403c6cb084","BusinessFunction","FAIR Workflow Support","",""
"id-c45faf95dc9142ac9d8b429fe3393116","BusinessFunction","FAIR Workflow Support","",""
"id-a20c7c7d11684fe29996e6daa41bdada","BusinessFunction","Infrastructure Governance","",""
"id-77a46bd4b2b84f639fb085c3df4d63c4","BusinessFunction","Preservation Support","",""
"id-8c56071da1414281a3487296162d0261","BusinessFunction","Project consulting","",""
"id-ef13a534b9b4448e95c8a732a1610e33","BusinessInteraction","Business Interaction","",""
"id-8f352ac54d33412580bf6b3c02d5f3dd","BusinessProcess","Business Process","",""
"id-239e3e8392cf4162a5e1a1aed3d40574","BusinessProcess","Business Process","",""
"id-3fe7012b28a64522885ad34d16b38e9e","BusinessProcess","Consultation and Training","",""
"id-712ac63d0d384d41aca7e118d1ef40e3","BusinessProcess","Data Integration & Interoperability","The process of combining data from different sources and ensuring it works together in a seamless, interoperable manner, allowing systems to share and interpret data effectively.",""
"id-3e0d6db1da5e44a59fd0b5bcb3acae2d","BusinessProcess","Data Management Plan","Encompasses the creation and maintenance of the research plan and data management plan, including preparing for data acquisition, selecting formats and storage solutions, and anticipating sharing and dissemination strategies to guide data management throughout the research lifecycle.",""
"id-0cedc438075c49f1ae5cdb4771d5e40b","BusinessProcess","Data Processing","Encompasses actions taken to refine and analyze raw or acquired data by researchers, using tools and programs, to yield processed data ready for observations and conclusions.",""
"id-8af1049318c844208418f585711460bd","BusinessProcess","Data Production","Focuses on the creation, collection, or acquisition of raw research data, either generated internally or sourced externally, through experimental or computational methods.",""
"id-abe24cf55eb84fad89a42d741c539391","BusinessProcess","Data Publication","Covers the external dissemination of both raw and processed research data, ensuring access for the wider community while adhering to policies on public sharing, use, and reuse.",""
"id-3b37e6acf19b486e8a82a3249f878231","BusinessProcess","Data Quality Monitoring","The process of ensuring that data meets defined standards of accuracy, consistency, and reliability, critical for effective decision-making and analysis.",""
"id-6a9889a99f0a465a951db3a4dabb04cb","BusinessProcess","FAIR Data Lifecycle","The process that encompasses all phases of research data management, from planning, collection, processing, preservation, to sharing and reuse adhering to FAIR and CARE principles.",""
"id-bf08418d3e0c41049222f8801215d7a5","BusinessProcess","FAIR Infrastructure Governance","The structured process of managing and regulating the infrastructure required for ensuring that data adheres to FAIR principles.",""
"id-951cb0a56d5e470aa0a036e260976291","BusinessProcess","Preserve, Discard, Reuse","Defines the processes for long-term data management, including archival or disposal of research data, ensuring compliance with records management practices and safe data handling at the end of its lifecycle.",""
"id-ee1741e5c1b740b6bedd87d79afdad59","BusinessProcess","Project Proposal","Establishes the strategic direction and decisions for an organizationâ€™s research data program, integrating it with broader data governance strategies to align with organizational goals.",""
"id-7397d468624c4601a4c78b20be01f5b0","BusinessProcess","Reference & Master Data Management","The process of managing key data entities (reference and master data) that are critical for the operation of the research infrastructure. This process includes definition of common terminologies, taxonomies and codelists using standards and best practices from the research domain.",""
"id-613bbde66b2f4411b1bc940727efe26e","BusinessProcess","Research Data Infrastructure","",""
"id-ae0c3301ad50478cbc4da11843a62f35","BusinessService","Research Data Infrastructure","",""
"id-70c768b3ec8340d6b8bc23bc19cd493d","ApplicationComponent","Data Cleaning Component","A system or software component responsible for the cleaning and preprocessing of raw data before it is used for analysis or further processing.",""
"id-87e5e576bda3450982d5d95f0a06c017","ApplicationComponent","Data Harmonization Component","A software system or module designed to ensure that data from different sources conforms to a common format or structure, enabling interoperability and consistency.",""
"id-91e9a71c2a0649029e94e0f3a01941f3","ApplicationComponent","Data Ingestion Component","A system or tool responsible for collecting and integrating data from various sources into a central repository for analysis or further processing.",""
"id-9c9d73d6b03e44bb81c563faeddd067f","ApplicationComponent","Data Processing Component","A system or tool that applies transformations, aggregations, and calculations to raw data, preparing it for analysis or reporting.",""
"id-5cb30378e23b49e8850b5291051093e2","ApplicationComponent","Fair Publication Component","A system or tool that manages the process of publishing data in a manner that conforms to FAIR principles, ensuring that data is Findable, Accessible, Interoperable, and Reusable.",""
"id-dc779c8d0f3b4cb19843e84da720ce8e","ApplicationComponent","FAIR Validation Component","A tool or system that checks whether data adheres to FAIR principles, ensuring compliance and quality of data publication.",""
"id-9f381b4cbe7b42019d1c47047e84ce43","ApplicationComponent","Ingestion Pipeline Component","A module or system responsible for managing the sequence of steps involved in the collection and integration of data from various sources into a central system.",""
"id-0ab8bb7bb4104a7bbb7f1d04f8b1f5be","ApplicationProcess","Access control","The process of managing how the raw data sources are accessed",""
"id-34a21f7e09834ba189d1d7227580c5dc","ApplicationProcess","Cleaning","The process of detecting and correcting (or removing) corrupt or inaccurate records from a dataset, improving data quality.",""
"id-a603e6ad55a8440c809ea1e967a8f13b","ApplicationProcess","Collection","The process of gathering and storing data from different sources for further analysis or processing.",""
"id-c9a11b59f8cc49ae8fc793204a04aece","ApplicationProcess","Data Harmonization Pipeline","A structured process that ensures data is cleaned, harmonized and transformed into more usable format for ease of use across different systems or databases.",""
"id-1d1d9b177a844032b47ac8dc1f23004b","ApplicationProcess","Data preservation","The process of maintaining and safeguarding data to ensure its long-term accessibility and usability.",""
"id-60c63384392e4b34b32e80255882dff9","ApplicationProcess","Data Processing Pipeline","A sequence of operations to collect, process and transform data into a well-defined format ensuring fit-for-purpose quality, often through a combination of software applications and processes.",""
"id-36d14e362ca94cb08ce2d07fabe0c03f","ApplicationProcess","Deduplication","The process of identifying and removing duplicate records from a dataset to ensure uniqueness and data quality.",""
"id-6154fc708d304c598d2ffa53a05c04b8","ApplicationProcess","Fair Publication Pipeline","The structured workflow for publishing data in a manner that adheres to FAIR principles (Findable, Accessible, Interoperable, and Reusable).",""
"id-1673fa01d20040009a20d9985bd883cc","ApplicationProcess","FAIR validation","The process of verifying whether data adheres to FAIR principles, ensuring it is findable, accessible, interoperable, and reusable.",""
"id-915dd4979db44944a2bc0efcb46ee84e","ApplicationProcess","Ingestion frequency","The rate at which new data is collected and integrated into a system or database for further processing.",""
"id-a34b7352238e433ebfd7d141d2ed3e35","ApplicationProcess","Ingestion Pipeline","A sequence of steps that facilitate the input and integration of data into a system for cleaning, processing and further analysis.",""
"id-22ac88841a6e4ca58af3784d9a9efefe","ApplicationProcess","Interoperable metadata","Metadata that is structured in a way that allows it to be used and understood across different systems, promoting data sharing and reuse.",""
"id-4a9a49b10a9a4d60ad1e12891c4ea13b","ApplicationProcess","Persistent identifiers","Unique and persistent identifiers assigned to data or digital objects to ensure their long-term accessibility and referenceability, such as URN, DOI and ORCID",""
"id-ecbfdc07595e440ea14e7a22e8a5fd2e","ApplicationProcess","Processing","The sequence of actions applied to data to analyze, enrich and convert the data to support the intended use case",""
"id-9aa10889239c4757902fcca68e6d9a89","ApplicationProcess","Synthesizing","The process of combining different data sources to generate new insights or data products.",""
"id-2d1ad67f7a0d4a51b1f57ce02f6442ff","ApplicationProcess","Transformation","The process of converting data from one format, structure, or model to another for compatibility or analysis purposes.",""
"id-bc6a67bc055f4598be6300ce51b18d64","ApplicationProcess","Validation","The process of checking the accuracy and integrity of data to ensure it meets the required standards and specifications.",""
"id-1ccb6f7ae3cb4cafa25379d91aa9ee34","ApplicationProcess","Verification","The process of confirming that data or processes meet defined requirements and specifications, typically in quality assurance.",""
"id-f3b8a8e02e3e4d259845b678c399fa27","ApplicationProcess","Workflow Management","The process of organizing and optimizing the flow of tasks and information in a data processing pipeline or system.",""
"id-146e93c311164f37b9770f4f656ce6ed","ApplicationService","Clean Data Source","A source of data that has been cleaned to remove errors, inconsistencies, and redundancies, ensuring higher quality.",""
"id-563b2110ee0141a193d1bb867a2d029e","ApplicationService","Fair Data Source","A data source that adheres to the FAIR principles (Findable, Accessible, Interoperable, and Reusable), ensuring data quality and compliance with FAIR standards.",""
"id-10ca9fa9cd6e4b1abc7f0fdb40d07e80","ApplicationService","Ingested Data Source","A data source that has been collected and integrated into a system for analysis or further processing.",""
"id-aa513e51053545c0b75876b8acc50b2b","ApplicationService","Raw Data Source","A source of unprocessed or untransformed data, typically collected directly from the origin systems or devices.",""
"id-d0911f734bb64711b84df76baad8b070","ApplicationService","Smart Data Source","A data source that has been enriched with additional context, metadata and documentation to enable efficient data reuse and more advanced analysis or decision-making. This is typically domain spesific or fit-for-purpose enterpise level data that is well documented and ready to be used within a bounded context using the documentation and tools provided with the data.",""
"id-75da87ec51004d0c8ff803991521ba5a","DataObject","Cleaned Data","Data that has undergone a cleaning process to remove errors, inconsistencies, and duplicate entries, ensuring higher quality and usability.",""
"id-2af4bb4d64fd4f41a647f5fe91530374","DataObject","Data Graph","A structured representation of data in a graph format, showing relationships between entities, typically used in graph databases or semantic web applications.",""
"id-9317da0b32054394b0680f2c418ebedc","DataObject","Data Product","A product or output that is generated from processing or analyzing raw data, designed to provide insights, services, or solutions.",""
"id-c9d36edb264f49e385b3c8e552b63736","DataObject","Data Streams","Continuous flows of data generated by various sources, often in real-time, used for monitoring, analysis, and decision-making.",""
"id-42f04fc92848404ba2f3e3c851eec223","DataObject","Digital Twin","A digital replica of a physical entity, process, or system used for simulation, analysis, and monitoring.",""
"id-ae6d47fdffbc4e95afc0f83b15b94244","DataObject","Dumb Data","Data that lacks context, structure, or meaningful metadata, making it difficult to use or interpret effectively.",""
"id-1476dd75986748bab22c6afdee244c25","DataObject","Dumb Data Lake","A storage repository that holds a vast amount of raw data in its native format, typically without any preprocessing or structuring.",""
"id-85352c8f06cd4a9eb77f53b28aa6bb5d","DataObject","FAIR Data","Data that is Findable, Accessible, Interoperable, and Reusable, adhering to the FAIR principles.",""
"id-c939c8998d2c4b538a3bfad7feadb7ba","DataObject","Fair Data Workflow","A set of processes and procedures designed to handle data in a manner that adheres to FAIR principles.",""
"id-f32b97627eb445d08c375dd18905fc96","DataObject","Fair Digital Object","A FAIR digital object is a unit composed of data that is a sequence of bits, or a set of sequences of bits, each of the sequences being structured (typed) in a way that is interpretable by one or more computer systems, and having as essential elements an assigned globally uniqueandpersistent identifier (PID), a type definition for the object as a whole and a metadata description (which itself can be another FAIR digital object) of the properties of the object, making the whole findable, accessible, interoperable and reusable both by humans and computers for the reliable interpretation and processing of the data represented by the object (TSIG FDO WG).",""
"id-8614077189064d3288d7ad1c16638a44","DataObject","Fair Research Dataset","A research dataset that complies with FAIR principles, making it easily discoverable and usable by others.",""
"id-026049dfa8ad4d648c98a3ddeb62f8b2","DataObject","Harmonized Data","Data that has been standardized and integrated from multiple sources to ensure consistency and compatibility across datasets.",""
"id-4e1b7de8be1b4931a6d8e8ef74b31a80","DataObject","Ingested Data","Data that has been collected and integrated into a system for further processing or analysis.",""
"id-53926347263c49e2871029dc426b9616","DataObject","Master Data","Critical business data that is essential for operations, often shared across multiple systems and processes within an organization.",""
"id-db86e452bf434779b1a1d4605322cbe3","DataObject","Querable Data Stream","A data stream that can be queried or accessed in real-time for analysis or monitoring purposes.",""
"id-09ef67576bec497e902077429930704b","DataObject","Querable Structured Data","Structured data that can be easily queried, analyzed, and used in various applications and systems.",""
"id-78aeb37f109f4d56ab0bc005fda96738","DataObject","Raw Data","Unprocessed data that has been collected directly from the source without any transformation, cleaning, or aggregation.",""
"id-3e14fb1e68b94269bfb315aff73ff352","DataObject","Smart Data","Data that has been enriched with additional context or metadata to enhance its value and facilitate advanced analysis or decision-making.",""
"id-4bbc3513e1b74bbea0a883ddde32332b","DataObject","Structured Data Dump","A collection of structured data exported from a system or database, typically used for backup, analysis, or migration purposes.",""
"id-b6008759853f4aaea90ffae132502475","Equipment","Hardware","Physical components of a computer system or data infrastructure, including servers, storage devices, and networking equipment.",""
"id-5278d336af93492ca7f30b19e1f6b16c","Material","Material","",""
"id-7153e8650e444bc0904025a9bcd52d10","TechnologyService","","",""
"id-da9411f83cb741f687c78ccfd4698e48","TechnologyService","Access Management","Services and tools that manage user access to systems and data, ensuring proper authentication and authorization. Access can be managed on service, API or dataset level using Resource Entitlement Management Systems.",""
"id-273555cd3fd54f03b1e41868aaf8038b","TechnologyService","Analytics","Data storage that integrates data from multiple sources, optimized for reporting and analysis.",""
"id-6ca25261b2dd434e8a4cd9d5985434de","TechnologyService","APIs","Application Programming Interfaces that allow different software applications to communicate and interact with each other, enabling integration and functionality sharing.",""
"id-26bd7641ac8f457ebb69da38091bc24f","TechnologyService","Application Interface","The point of interaction between different software applications, enabling them to communicate and exchange data.",""
"id-d2f13b5c3f714d2e8e4f6ca404500900","TechnologyService","Code Repository","A storage location for software code, enabling version control, collaboration, and management of codebases.",""
"id-44f6124149b248e7ae79c676915b6532","TechnologyService","Collaborative Wiki","A web-based platform that allows multiple users to create, edit, and share content collaboratively in real-time.",""
"id-026c5eb4690d449ba672256fdf74fa48","TechnologyService","Columnar","Database where data is stored in columns instead of rows to optimize certain types of queries, analytic workflows and data manipulation operations.",""
"id-7537961dc41145acaf2cd61891a86902","TechnologyService","Data Governance Systems","Software systems designed to manage, monitor, and enforce data governance policies and practices within an organization.",""
"id-06cc1567f13a4f60a1c4c0678b17646e","TechnologyService","Data ingestion","The process of importing, transferring, loading, and processing data for later use or storage in a database or data warehouse.",""
"id-6b4c996982fd471c877ec90e82e9f606","TechnologyService","Data Lineage Systems","The documentation of the origin, lineage, and history of data, ensuring its authenticity and traceability throughout its lifecycle.",""
"id-d8882c4175d34e89b7bd05fc7df9a361","TechnologyService","Data mining","The practice of examining large datasets to discover patterns, trends, and insights that can inform decision-making.",""
"id-f83bb093044945e69fe4c00f6118793b","TechnologyService","Data Processing Platform","A software platform that provides tools and infrastructure for processing, analyzing, and managing large volumes of data.",""
"id-e2e3bd37f1c94f92a24a96364ba0e3bb","TechnologyService","Data Storage","Systems and formats used to store data, including different types of databases, data warehouses, data lakes, cloud storage solutions and transaction formats. The list is endless and the high level categorization is mainly used to exemplify that there are different types of data storage and transaction formats to suit different needs.",""
"id-c9b2fc69fa8c4c4d99e0fc9fee965da0","TechnologyService","Data Workflow Repository","A system that stores and manages workflows related to data processing, ensuring efficient and repeatable data operations.",""
"id-8156810c5e814634b46ec03675cd81de","TechnologyService","Database","An organized collection of structured information or data, typically stored electronically in a computer system.",""
"id-2a5794037724434191ae58b95b64c332","TechnologyService","Devices","Hardware tools and equipment used for data collection, processing, and storage, such as sensors, computers, and mobile devices.",""
"id-3bd2c7355e9c4cb99280434118f802c0","TechnologyService","Dimensional","Relational database that uses a dimensional data model to organize data. This model uses fact tables and dimension tables using different schema models such as star model, snowflake, galaxy or data cube schema. A dimensional database is the optimal type of database for data warehousing.",""
"id-bfc3c6e9fc554958a0c2e28e56c7198c","TechnologyService","Document","A type of database designed to store, retrieve, and manage document-oriented information, typically in formats like JSON or XML.",""
"id-431a07ea060d44a9933b3d40b525c006","TechnologyService","Documentation & Support Systems","Software tools and systems that provide documentation, help resources, and support for users managing data systems and infrastructure.",""
"id-ac94d2be5977485d8adbabbe1c3d7679","TechnologyService","Domain solutions","Specialized software or systems designed to address specific needs or challenges within a particular domain or industry.",""
"id-e105f5f43d194b8f824c3ce429d49687","TechnologyService","Event streaming","The continuous flow of data generated by events, typically processed in real-time for immediate analysis and response.",""
"id-ba17b004421f4993859e4ae90547408f","TechnologyService","FAIR publication system","A system designed to publish data in accordance with FAIR principles, ensuring data is findable, accessible, interoperable, and reusable.",""
"id-84bc574b7dd54a0aa15da7f3c796ee50","TechnologyService","Fairdata platform","FAIR data infrastucture designed to manage, store, and provide access to FAIR data, ensuring compliance with FAIR principles.",""
"id-f875106b325d481e8f2fb43858f991fb","TechnologyService","Filesystem","A method and data structure that an operating system uses to control how data is stored and retrieved on storage devices.",""
"id-109f53b9df184ca49019553bc74fb1ab","TechnologyService","Graph","A type of database that uses graph structures with nodes, edges, and properties to store and represent data, enabling data integration and efficient querying of relationships. Different types of graph databases like RDF, propery graph and in-memory graph databases offer diverse functionalities suitable for specialized applications to support different use cases that use high variety, interconnected and dynamic data from multiple sources.",""
"id-630f794aff154986884ee9773ef1aa6c","TechnologyService","Identity Management","Services and systems that manage user identities and control access to resources based on authenticated identities.",""
"id-74b0e46454e54b46a1fd98fca10c93bf","TechnologyService","Issues & Feedback","Systems and processes that collect, manage, and respond to user-reported issues and feedback regarding data systems and services.",""
"id-ff996410103a4200bfaadc60a4f14fe2","TechnologyService","Key value","A type of NoSQL database that stores data as a collection of key-value pairs, allowing for simple and fast data retrieval based on unique keys.",""
"id-a8907ec881b641849675fd0a55d49b03","TechnologyService","Learning Portal","An online platform that provides educational resources, training materials, and learning modules for users and stakeholders.",""
"id-91388971548f455bb3dd9e191c5e3248","TechnologyService","Ledger","Immutable record-keeping system that is permanent and immune to data corruption and provides strong gaurantees about the lineage of data. Ledgers can be both centralized or decentralized.",""
"id-1ac42d9c263e413788497e7b843dae57","TechnologyService","Machine Actionable Interface","Interfaces that allow machines to interpret and act upon data or commands without human intervention, facilitating automation and integration.",""
"id-a189329081114f9bac28324b35626448","TechnologyService","Machine learning","A subset of artificial intelligence that involves the development of algorithms that can learn from and make predictions or decisions based on data.",""
"id-d813c9bd8df249a6890e6398678933a9","TechnologyService","Metadata Crosswalks","Tools or processes that map metadata elements from one schema or standard to another, enabling interoperability and data integration across different systems.",""
"id-0252e12979eb4c4abd733a4057f995c1","TechnologyService","Metadata Management Systems","Systems that manage metadata, ensuring it is properly collected, stored, and accessible for data governance and usage.",""
"id-fb72334b1cbb4f26a4346f83cf9e871c","TechnologyService","Model & Schema Repositories","Structured representations of data that define the organization, relationships, and constraints of data elements within a system or application.
",""
"id-9c47bf671eb84440969d6330e957fa50","TechnologyService","Notebooks","",""
"id-f6827c8b7a4c470b9fb420f877f0e676","TechnologyService","Object ","A storage architecture that manages data as objects, each containing the data itself, metadata, and a unique identifier, suitable for large-scale unstructured data.",""
"id-ca8ec5464dbb408d897ca621c79c40b0","TechnologyService","Ontology & Linked Data Platforms","Formal representations of knowledge (Classes, properties and instances) as a set of concepts and the relationships between them, used to model domain knowledge and integrating data from multiple sources to semantically interoperable data model.",""
"id-11de28e3ed4b4742af8d381b0e7072c1","TechnologyService","Operational","Data storage systems designed to update data in real-time",""
"id-74d6f68c268441b4bd8bd57ee7943398","TechnologyService","PID Management","Process and systems for managing Persistent Identifiers (PIDs) to ensure unique, long-lasting references to digital objects or data.",""
"id-66e62ac5640b4a83ac4960407b554ca9","TechnologyService","PID Resolver","A system or service that resolves Persistent Identifiers (PIDs) to their corresponding digital objects or data locations.",""
"id-c736dc90f3c24ab793c16148170cbd26","TechnologyService","Preservation system","Systems and processes designed to maintain and protect digital data over time, ensuring its accessibility and integrity for future use.",""
"id-4dcab330d90a43b9a4c6efa61be0a2ae","TechnologyService","Process engine","Software that manages and executes business processes, often using defined workflows to coordinate tasks and data flows.",""
"id-50bb9b179745438899a2b450e22f0719","TechnologyService","Property graph","",""
"id-bced1fc6c68f469d8351db970a20b630","TechnologyService","Provenance Systems","Systems that track the origins, movement, and transformations of data. These include data lineage systems as well as the provenance of code and the deployment and usage of the systems used to manage the data.",""
"id-676be3a1c4f146eb8e33e1ba9ce65bf0","TechnologyService","Publication system","Systems that manage the dissemination and distribution of data, content, or research outputs to end-users or the public.",""
"id-bdf72d39edc244b480d567d93a17064c","TechnologyService","Publishing platform","Software systems that facilitate the publishing and distribution of data, content, or services to end-users.",""
"id-fe96eda9bc5745988305daa07a6d1517","TechnologyService","Quality assurance","Processes and systems designed to ensure that data and data-related processes meet defined quality standards and requirements.",""
"id-c20755df98804d7781acbc2950360252","TechnologyService","Reference Data & Taxonomies","Standardized sets of data and classification systems that provide a consistent framework for data categorization and analysis across different systems.",""
"id-f203efbf44b14db8bde80c93a9e16978","TechnologyService","Relational","",""
"id-64e4b2689bd1458e94dbd4d2a1a6cc4d","TechnologyService","Research notebooks","Interactive notebooks, digital tools or platforms designed to support and enhance scientific research, experimentation, and analysis. They function as a dynamic environment where researchers can record, execute, and visualize code, document processes, and share results in an integrated and collaborative manner.",""
"id-276dca076d374fda9983ba8916287c58","TechnologyService","Scientific computing","The use of advanced computing capabilities such as parallel processing or quantum computing to understand and solve complex scientific problems through simulations, modeling, and data analysis.",""
"id-7f21e8694d9447789c7d9f1691e35d43","TechnologyService","Semantic Artefact Repositories","Semantic artifact repositories enable both humans and machines to access, understand, and use this structured knowledge. Semantic artifacts are formal, machine readable and actionable representations of knowledge, used to capture and structure information in a domain. Examples include ontologies, terminologies, taxonomies, thesauri, vocabularies, metadata schemas, data models and data mappings.",""
"id-6e6c4eee0d5240dca093c76fa3d59a89","TechnologyService","Sensors","Devices that detect and measure physical properties, converting them into data that can be analyzed and used for monitoring and decision-making.",""
"id-fab0766e05ff4f0ca57e8e5c91713780","TechnologyService","Source systems","Original systems where data is created or initially stored, serving as the primary data sources for data integration and processing.",""
"id-402eceeac86c4876b7ba8514edd130dd","TechnologyService","Spatiotemporal","Designed to efficiently store, query, and process spatial and temporal data, such as observations, time series, geoinformation, historical locations and events etc.",""
"id-4839c070d92d432297e0d162b4a7ab39","TechnologyService","Specialized","Data storage system designed and optimized for different use cases. This type of data storages can also be hybrid, multimodal and used both in operational or analytic use cases.",""
"id-dfc4619d1573425b872404e1efc8b1b8","TechnologyService","Staging System","A system used to temporarily store data before it is processed and moved to a final destination, often used as a first step in data cleaning, data warehousing and integration platforms.",""
"id-0666b6535dd04bd19a3368762023fd31","TechnologyService","Technology Service","",""
"id-357761f8210741f38cba78a5678f37fe","TechnologyService","Technology Service","",""
"id-308d225dd69d4b2e898b3a2ba28472bb","TechnologyService","Validation Tools","Data quality management tools that monitor and validate metadata to identify discrepancies, missing fields, or inconsistencies.",""
"id-0c03d93902ee4304aa394170cecb0682","TechnologyService","Vector","Data structures used to store and manipulate mathematical vectors, often used in machine learning and data analysis applications.",""
"id-e361c38b14034cb4a03d7378864bf6be","TechnologyService","Virtual Research Environment","A specialized data processing platform that provides researchers with tools, resources, and collaborative spaces to conduct and manage research activities.",""
"id-e8fcd9b24c0444309a13a54eace66d26","TechnologyService","Visualisation platforms","Tools or systems designed to create, manage, and interact with visual representations of data. These platforms facilitate the transformation of complex datasets into graphical or visual forms such as charts, graphs, maps, dashboards, and interactive visuals. The goal of these platforms is to make data more understandable, accessible, and actionable, allowing users to explore, analyze, and communicate insights effectively.",""